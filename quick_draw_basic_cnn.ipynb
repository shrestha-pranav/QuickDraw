{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quick_draw_basic_cnn",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "-dh5p9heunLa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install kaggle cli\n",
        "!pip install kaggle --upgrade  > /dev/null\n",
        "!git clone https://gist.github.com/soulitzer/810d10e3b42666b885715bb872b3ea10 data >/dev/null 2>&1\n",
        "!rm -rf ~/.kaggle && mkdir ~/.kaggle/\n",
        "!cp data/kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OheuFaWXujxz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download files\n",
        "!kaggle competitions download -c quickdraw-doodle-recognition -f test_simplified.csv > /dev/null\n",
        "!kaggle competitions download -c quickdraw-doodle-recognition -f train_simplified.zip > /dev/null\n",
        "# !kaggle competitions download -c quickdraw-doodle-recognition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fwrbP_0KzkIj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3caf7d40-af1b-4374-e243-2eb177d4c09a"
      },
      "cell_type": "code",
      "source": [
        "# Unzip - takes a couple min to run\n",
        "!mkdir train_simple_csvs\n",
        "# !mkdir train_raw_csvs\n",
        "# !unzip train_raw.zip -d train_raw_csvs > /dev/null\n",
        "!unzip train_simplified.zip -d train_simple_csvs > /dev/null"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘train_simple_csvs’: File exists\n",
            "replace train_simple_csvs/fence.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yb9QSH14NmpW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install dask[bag] --upgrade > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lDlP1qYCNUJI",
        "colab_type": "code",
        "outputId": "6c1ed95f-e6b9-4e50-9be7-708e7657a659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import re\n",
        "import ast\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from PIL import Image, ImageDraw \n",
        "from tqdm import tqdm\n",
        "from dask import bag\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "frttDweeC7br",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set label dictionary and params\n",
        "classfiles = os.listdir('./train_simple_csvs')\n",
        "numstonames = {i: v[:-4].replace(\" \", \"_\") for i, v in enumerate(classfiles)}\n",
        "num_classes = 340  \n",
        "imheight, imwidth = 32, 32  \n",
        "ims_per_class = 2000 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KyEGqH4DC9dA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Conversion to image from sequence\n",
        "def draw_it(strokes):\n",
        "    image = Image.new(\"P\", (256,256), color=255)\n",
        "    image_draw = ImageDraw.Draw(image)\n",
        "    for stroke in ast.literal_eval(strokes):\n",
        "        for i in range(len(stroke[0])-1):\n",
        "            image_draw.line([stroke[0][i], \n",
        "                             stroke[1][i],\n",
        "                             stroke[0][i+1], \n",
        "                             stroke[1][i+1]],\n",
        "                            fill=0, width=5)\n",
        "    image = image.resize((imheight, imwidth))\n",
        "    return np.array(image)/255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HbsYVRQ_DB1u",
        "colab_type": "code",
        "outputId": "3774593c-7988-4e8e-dbce-a11d43a2b074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Get training and testing data\n",
        "train_grand = []\n",
        "class_paths = glob('./train_simple_csvs/*.csv')\n",
        "for i,c in enumerate(tqdm(class_paths[0: num_classes])):\n",
        "    train = pd.read_csv(c, usecols=['drawing', 'recognized'], nrows=ims_per_class*5//4)\n",
        "    train = train[train.recognized == True].head(ims_per_class)\n",
        "    imagebag = bag.from_sequence(train.drawing.values).map(draw_it)\n",
        "    \n",
        "    trainarray = np.array(imagebag.compute()) \n",
        "    trainarray = np.reshape(trainarray, (ims_per_class, -1))    \n",
        "    labelarray = np.full((train.shape[0], 1), i)\n",
        "    trainarray = np.concatenate((labelarray, trainarray), axis=1)\n",
        "    train_grand.append(trainarray)\n",
        "    \n",
        "train_grand = np.array([train_grand.pop() for i in np.arange(num_classes)])\n",
        "train_grand = train_grand.reshape((-1, (imheight*imwidth+1)))\n",
        "\n",
        "del trainarray\n",
        "del train"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 340/340 [10:34<00:00,  1.88s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "vwDTw9LU3tSU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valfrac = 0.1\n",
        "cutpt = int(valfrac * train_grand.shape[0])\n",
        "\n",
        "np.random.shuffle(train_grand)\n",
        "y_train, X_train = train_grand[cutpt: , 0], train_grand[cutpt: , 1:]\n",
        "y_val, X_val = train_grand[0:cutpt, 0], train_grand[0:cutpt, 1:]\n",
        "\n",
        "del train_grand"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NwlKnhAU3r8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d96d56c3-6871-4b19-a1f6-d02f16ee45ac"
      },
      "cell_type": "code",
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "X_train = X_train.reshape(X_train.shape[0], imheight, imwidth, 1)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
        "X_val = X_val.reshape(X_val.shape[0], imheight, imwidth, 1)\n",
        "\n",
        "print(y_train.shape, \"\\n\",\n",
        "      X_train.shape, \"\\n\",\n",
        "      y_val.shape, \"\\n\",\n",
        "      X_val.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(612000, 340) \n",
            " (612000, 32, 32, 1) \n",
            " (68000, 340) \n",
            " (68000, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YOr6r8HlDEOZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Top-3 classification accuracy\n",
        "def top_3_accuracy(x,y): \n",
        "    t3 = top_k_categorical_accuracy(x,y, 3)\n",
        "    return t3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SA855QzEwb9j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1244
        },
        "outputId": "f3969c3e-d826-4290-bbd0-5a4a422778e8"
      },
      "cell_type": "code",
      "source": [
        "# Basic CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(imheight, imwidth, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(680, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy', top_3_accuracy])\n",
        "\n",
        "model.fit(x=X_train, y=y_train,\n",
        "          batch_size = 512,\n",
        "          epochs = 22,\n",
        "          validation_data = (X_val, y_val),\n",
        "          callbacks = callbacks,\n",
        "          verbose = 1)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 680)               2785960   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 680)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 340)               231540    \n",
            "=================================================================\n",
            "Total params: 3,036,316\n",
            "Trainable params: 3,036,316\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 612000 samples, validate on 68000 samples\n",
            "Epoch 1/22\n",
            "612000/612000 [==============================] - 115s 189us/step - loss: 3.4009 - acc: 0.2638 - top_3_accuracy: 0.4343 - val_loss: 2.3344 - val_acc: 0.4454 - val_top_3_accuracy: 0.6551\n",
            "Epoch 2/22\n",
            "612000/612000 [==============================] - 108s 177us/step - loss: 2.5561 - acc: 0.3940 - top_3_accuracy: 0.6030 - val_loss: 2.0818 - val_acc: 0.4943 - val_top_3_accuracy: 0.7017\n",
            "Epoch 3/22\n",
            "612000/612000 [==============================] - 108s 177us/step - loss: 2.3663 - acc: 0.4294 - top_3_accuracy: 0.6412 - val_loss: 1.9594 - val_acc: 0.5195 - val_top_3_accuracy: 0.7261\n",
            "Epoch 4/22\n",
            "612000/612000 [==============================] - 108s 177us/step - loss: 2.2553 - acc: 0.4491 - top_3_accuracy: 0.6625 - val_loss: 1.8861 - val_acc: 0.5360 - val_top_3_accuracy: 0.7419\n",
            "Epoch 5/22\n",
            "612000/612000 [==============================] - 109s 177us/step - loss: 2.1767 - acc: 0.4643 - top_3_accuracy: 0.6789 - val_loss: 1.8501 - val_acc: 0.5428 - val_top_3_accuracy: 0.7460\n",
            "Epoch 6/22\n",
            "612000/612000 [==============================] - 109s 177us/step - loss: 2.1152 - acc: 0.4761 - top_3_accuracy: 0.6900 - val_loss: 1.7922 - val_acc: 0.5512 - val_top_3_accuracy: 0.7569\n",
            "Epoch 7/22\n",
            "612000/612000 [==============================] - 108s 177us/step - loss: 2.0624 - acc: 0.4862 - top_3_accuracy: 0.7000 - val_loss: 1.7644 - val_acc: 0.5568 - val_top_3_accuracy: 0.7616\n",
            "Epoch 8/22\n",
            "612000/612000 [==============================] - 109s 177us/step - loss: 2.0156 - acc: 0.4951 - top_3_accuracy: 0.7086 - val_loss: 1.7399 - val_acc: 0.5631 - val_top_3_accuracy: 0.7673\n",
            "Epoch 9/22\n",
            "612000/612000 [==============================] - 108s 177us/step - loss: 1.9781 - acc: 0.5015 - top_3_accuracy: 0.7157 - val_loss: 1.7331 - val_acc: 0.5638 - val_top_3_accuracy: 0.7668\n",
            "Epoch 10/22\n",
            "612000/612000 [==============================] - 108s 177us/step - loss: 1.9437 - acc: 0.5091 - top_3_accuracy: 0.7223 - val_loss: 1.7012 - val_acc: 0.5691 - val_top_3_accuracy: 0.7729\n",
            "Epoch 11/22\n",
            "612000/612000 [==============================] - 109s 178us/step - loss: 1.9136 - acc: 0.5143 - top_3_accuracy: 0.7276 - val_loss: 1.6919 - val_acc: 0.5722 - val_top_3_accuracy: 0.7732\n",
            "Epoch 12/22\n",
            "612000/612000 [==============================] - 109s 178us/step - loss: 1.8841 - acc: 0.5202 - top_3_accuracy: 0.7330 - val_loss: 1.6710 - val_acc: 0.5741 - val_top_3_accuracy: 0.7777\n",
            "Epoch 13/22\n",
            "612000/612000 [==============================] - 108s 177us/step - loss: 1.8618 - acc: 0.5249 - top_3_accuracy: 0.7378 - val_loss: 1.6730 - val_acc: 0.5759 - val_top_3_accuracy: 0.7777\n",
            "Epoch 14/22\n",
            "612000/612000 [==============================] - 108s 177us/step - loss: 1.8354 - acc: 0.5305 - top_3_accuracy: 0.7427 - val_loss: 1.6535 - val_acc: 0.5796 - val_top_3_accuracy: 0.7808\n",
            "Epoch 15/22\n",
            "612000/612000 [==============================] - 108s 177us/step - loss: 1.8139 - acc: 0.5338 - top_3_accuracy: 0.7462 - val_loss: 1.6576 - val_acc: 0.5792 - val_top_3_accuracy: 0.7809\n",
            "Epoch 16/22\n",
            "612000/612000 [==============================] - 108s 176us/step - loss: 1.7961 - acc: 0.5373 - top_3_accuracy: 0.7497 - val_loss: 1.6467 - val_acc: 0.5801 - val_top_3_accuracy: 0.7818\n",
            "Epoch 17/22\n",
            "612000/612000 [==============================] - 108s 177us/step - loss: 1.7755 - acc: 0.5417 - top_3_accuracy: 0.7531 - val_loss: 1.6379 - val_acc: 0.5818 - val_top_3_accuracy: 0.7829\n",
            "Epoch 18/22\n",
            "612000/612000 [==============================] - 108s 177us/step - loss: 1.7595 - acc: 0.5446 - top_3_accuracy: 0.7562 - val_loss: 1.6348 - val_acc: 0.5832 - val_top_3_accuracy: 0.7838\n",
            "Epoch 19/22\n",
            "612000/612000 [==============================] - 106s 173us/step - loss: 1.7433 - acc: 0.5474 - top_3_accuracy: 0.7590 - val_loss: 1.6375 - val_acc: 0.5823 - val_top_3_accuracy: 0.7841\n",
            "Epoch 20/22\n",
            "612000/612000 [==============================] - 106s 173us/step - loss: 1.7292 - acc: 0.5499 - top_3_accuracy: 0.7625 - val_loss: 1.6316 - val_acc: 0.5837 - val_top_3_accuracy: 0.7852\n",
            "Epoch 21/22\n",
            "612000/612000 [==============================] - 105s 172us/step - loss: 1.7161 - acc: 0.5526 - top_3_accuracy: 0.7641 - val_loss: 1.6365 - val_acc: 0.5819 - val_top_3_accuracy: 0.7843\n",
            "Epoch 22/22\n",
            "612000/612000 [==============================] - 105s 172us/step - loss: 1.7049 - acc: 0.5552 - top_3_accuracy: 0.7663 - val_loss: 1.6284 - val_acc: 0.5846 - val_top_3_accuracy: 0.7864\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff75137b358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "gDhpJvDGr9gz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Modified Inception model \n",
        "custom_input = Input(shape=(32,32, 1))\n",
        "#inception_input = Conv2D(3, kernel_size=(1, 1), padding='same')(custom_input)\n",
        "\n",
        "base_model = keras.applications.MobileNet(\n",
        "    include_top=False, input_shape=(32, 32, 1), weights=None)\n",
        "\n",
        "x = Flatten()(base_model(custom_input))\n",
        "predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "head_model = Model(custom_input, predictions)\n",
        "\n",
        "# for layer in base_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# head_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1_fVfC86sBu7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "head_model.compile(optimizer=keras.optimizers.Adam(lr=0.002), loss='categorical_crossentropy', \n",
        "                   metrics=['accuracy', top_3_accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kDvN1Le4Mq_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "9410edbf-aa80-4538-e9c0-a5e50ca59a9d"
      },
      "cell_type": "code",
      "source": [
        "# Define Callbacks\n",
        "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, \n",
        "                                   verbose=1, mode='auto', min_delta=0.005, \n",
        "                                   cooldown=5, min_lr=0.0001)\n",
        "earlystop = EarlyStopping(monitor='val_top_3_accuracy', mode='max', patience=5) \n",
        "\n",
        "# Fit Model\n",
        "callbacks = [reduceLROnPlat, earlystop]\n",
        "\n",
        "head_model.fit(x=X_train, y=y_train,\n",
        "          batch_size = 512,\n",
        "          epochs = 22,\n",
        "          validation_data = (X_val, y_val),\n",
        "          callbacks = callbacks,\n",
        "          verbose = 1)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 612000 samples, validate on 68000 samples\n",
            "Epoch 1/22\n",
            "612000/612000 [==============================] - 195s 318us/step - loss: 3.6658 - acc: 0.1996 - top_3_accuracy: 0.3591 - val_loss: 7.0311 - val_acc: 0.0669 - val_top_3_accuracy: 0.1458\n",
            "Epoch 2/22\n",
            "612000/612000 [==============================] - 162s 264us/step - loss: 2.2838 - acc: 0.4232 - top_3_accuracy: 0.6497 - val_loss: 5.0527 - val_acc: 0.1475 - val_top_3_accuracy: 0.2852\n",
            "Epoch 3/22\n",
            "612000/612000 [==============================] - 162s 264us/step - loss: 1.9265 - acc: 0.4973 - top_3_accuracy: 0.7222 - val_loss: 2.3649 - val_acc: 0.4319 - val_top_3_accuracy: 0.6562\n",
            "Epoch 4/22\n",
            "612000/612000 [==============================] - 162s 264us/step - loss: 1.7485 - acc: 0.5361 - top_3_accuracy: 0.7569 - val_loss: 2.3196 - val_acc: 0.4343 - val_top_3_accuracy: 0.6577\n",
            "Epoch 5/22\n",
            "612000/612000 [==============================] - 162s 264us/step - loss: 1.6261 - acc: 0.5626 - top_3_accuracy: 0.7802 - val_loss: 2.1012 - val_acc: 0.4745 - val_top_3_accuracy: 0.6988\n",
            "Epoch 6/22\n",
            "612000/612000 [==============================] - 161s 264us/step - loss: 1.5273 - acc: 0.5843 - top_3_accuracy: 0.7983 - val_loss: 1.9049 - val_acc: 0.5121 - val_top_3_accuracy: 0.7326\n",
            "Epoch 7/22\n",
            "612000/612000 [==============================] - 162s 265us/step - loss: 1.4436 - acc: 0.6034 - top_3_accuracy: 0.8132 - val_loss: 2.9070 - val_acc: 0.3442 - val_top_3_accuracy: 0.5515\n",
            "Epoch 8/22\n",
            "612000/612000 [==============================] - 162s 265us/step - loss: 1.3690 - acc: 0.6191 - top_3_accuracy: 0.8263 - val_loss: 2.1078 - val_acc: 0.4857 - val_top_3_accuracy: 0.6988\n",
            "Epoch 9/22\n",
            "612000/612000 [==============================] - 162s 264us/step - loss: 1.3043 - acc: 0.6339 - top_3_accuracy: 0.8379 - val_loss: 1.7149 - val_acc: 0.5567 - val_top_3_accuracy: 0.7706\n",
            "Epoch 10/22\n",
            "612000/612000 [==============================] - 161s 264us/step - loss: 1.2443 - acc: 0.6476 - top_3_accuracy: 0.8482 - val_loss: 1.6984 - val_acc: 0.5606 - val_top_3_accuracy: 0.7753\n",
            "Epoch 11/22\n",
            "612000/612000 [==============================] - 162s 265us/step - loss: 1.1902 - acc: 0.6603 - top_3_accuracy: 0.8574 - val_loss: 1.8467 - val_acc: 0.5389 - val_top_3_accuracy: 0.7554\n",
            "Epoch 12/22\n",
            "612000/612000 [==============================] - 161s 264us/step - loss: 1.1391 - acc: 0.6715 - top_3_accuracy: 0.8663 - val_loss: 1.6841 - val_acc: 0.5719 - val_top_3_accuracy: 0.7826\n",
            "Epoch 13/22\n",
            "612000/612000 [==============================] - 161s 264us/step - loss: 1.0904 - acc: 0.6824 - top_3_accuracy: 0.8748 - val_loss: 1.6768 - val_acc: 0.5765 - val_top_3_accuracy: 0.7829\n",
            "Epoch 14/22\n",
            "612000/612000 [==============================] - 162s 264us/step - loss: 1.0452 - acc: 0.6927 - top_3_accuracy: 0.8816 - val_loss: 1.7146 - val_acc: 0.5762 - val_top_3_accuracy: 0.7829\n",
            "Epoch 15/22\n",
            "612000/612000 [==============================] - 162s 264us/step - loss: 1.0001 - acc: 0.7036 - top_3_accuracy: 0.8894 - val_loss: 1.7871 - val_acc: 0.5608 - val_top_3_accuracy: 0.7720\n",
            "Epoch 16/22\n",
            "611840/612000 [============================>.] - ETA: 0s - loss: 0.9574 - acc: 0.7138 - top_3_accuracy: 0.8961\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
            "612000/612000 [==============================] - 172s 281us/step - loss: 0.9575 - acc: 0.7138 - top_3_accuracy: 0.8961 - val_loss: 1.7049 - val_acc: 0.5783 - val_top_3_accuracy: 0.7873\n",
            "Epoch 17/22\n",
            "612000/612000 [==============================] - 172s 281us/step - loss: 0.7687 - acc: 0.7666 - top_3_accuracy: 0.9246 - val_loss: 1.6259 - val_acc: 0.6042 - val_top_3_accuracy: 0.8060\n",
            "Epoch 18/22\n",
            "612000/612000 [==============================] - 172s 281us/step - loss: 0.7025 - acc: 0.7839 - top_3_accuracy: 0.9341 - val_loss: 1.7163 - val_acc: 0.5982 - val_top_3_accuracy: 0.7989\n",
            "Epoch 19/22\n",
            "612000/612000 [==============================] - 172s 281us/step - loss: 0.6566 - acc: 0.7966 - top_3_accuracy: 0.9410 - val_loss: 1.7813 - val_acc: 0.5938 - val_top_3_accuracy: 0.7945\n",
            "Epoch 20/22\n",
            "612000/612000 [==============================] - 172s 281us/step - loss: 0.6167 - acc: 0.8073 - top_3_accuracy: 0.9465 - val_loss: 1.8269 - val_acc: 0.5914 - val_top_3_accuracy: 0.7940\n",
            "Epoch 21/22\n",
            "612000/612000 [==============================] - 172s 281us/step - loss: 0.5793 - acc: 0.8171 - top_3_accuracy: 0.9521 - val_loss: 2.0166 - val_acc: 0.5656 - val_top_3_accuracy: 0.7741\n",
            "Epoch 22/22\n",
            "612000/612000 [==============================] - 172s 281us/step - loss: 0.5465 - acc: 0.8266 - top_3_accuracy: 0.9567 - val_loss: 1.9303 - val_acc: 0.5892 - val_top_3_accuracy: 0.7902\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff735045390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "dUefojgby7qx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "root_dir = './train_simple_csvs/'\n",
        "files = [f for f in os.walk(root_dir)][0][2]\n",
        "for f in files:\n",
        "    label = '_'.join(f.split('.')[0].split(' '))\n",
        "    f_dir = root_dir + f \n",
        "    if label == 'The_Great_Wall_of_China':\n",
        "        df = pd.read_csv(f_dir)\n",
        "        break\n",
        "df[\"drawing\"].values[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2nSC6qqdE-kz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install tensorboard\n",
        "!pip install tensorboardcolab >/dev/null 2>&1\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9dl1aAKY7hxl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "USE_TENSORBOARD = True # Visualize training with Tensorboard\n",
        "if USE_TENSORBOARD:\n",
        "    tbc=TensorBoardColab()\n",
        "    props = dict(verbose=1, callbacks=[TensorBoardColabCallback(tbc)])\n",
        "else:\n",
        "    props = dict(verbose=1)\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train, X_train_alt, X_train_profile],\n",
        "    y_train,\n",
        "    batch_size = 128,\n",
        "    epochs = 100,\n",
        "    validation_data = ([X_val, X_val_alt, X_val_profile], y_val),\n",
        "    **props\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vmLqNGot1UtJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Print out graph of val acc if history is saved\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wz2pv2pvt4H9",
        "colab_type": "code",
        "outputId": "7d2b182b-17c2-4042-c639-c1a01ea34811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Save models\"\"\"\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = head_model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "files.download('model.json') \n",
        "    \n",
        "# serialize weights to HDF5\n",
        "head_model.save_weights(\"model.h5\")\n",
        "files.download('model.h5')\n",
        "\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IXPuM7-QPl98",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Load models\"\"\"\n",
        "\n",
        "from keras.models import model_from_json\n",
        "\n",
        "# load json and create model\n",
        "json_file = open('model (1).json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model (1).h5\")\n",
        "model = loaded_model\n",
        "\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2P2ltudvAOxI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Output Generator"
      ]
    },
    {
      "metadata": {
        "id": "10i5it1ox42r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"Save and download DataFrame\"\"\"\n",
        "with open(\"out.csv\", \"w\") as f:\n",
        "    out_df.to_csv(f, index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('out.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}